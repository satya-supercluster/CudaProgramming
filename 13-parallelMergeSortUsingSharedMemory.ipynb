{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c88391",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "%pip install nvcc4jupyter\n",
    "%load_ext nvcc4jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b375857c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsorted array:\n",
      "41 67 34 0 69 24 78 58 62 64 5 45 81 27 61 91 \n",
      "\n",
      "Sorted array:\n",
      "0 5 24 27 34 41 45 58 61 62 64 67 69 78 81 91 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N 16\n",
    "#define BLOCK_SIZE 16\n",
    "\n",
    "__global__ \n",
    "void mergeSortShared(int *d_input, int *d_output, int width) {\n",
    "    __shared__ int sharedMem[BLOCK_SIZE];\n",
    "\n",
    "    int tid = threadIdx.x;\n",
    "    int blockStart = blockIdx.x * blockDim.x;\n",
    "\n",
    "    if (blockStart + tid < N)\n",
    "        sharedMem[tid] = d_input[blockStart + tid];\n",
    "    __syncthreads();\n",
    "\n",
    "    // Bottom-up merge sort within shared memory\n",
    "    for (int step = 1; step < BLOCK_SIZE; step *= 2) {\n",
    "        int start = tid * 2 * step;\n",
    "        if (start < BLOCK_SIZE) {\n",
    "            int mid = min(start + step, BLOCK_SIZE);\n",
    "            int end = min(start + 2 * step, BLOCK_SIZE);\n",
    "\n",
    "            // Merge two sorted halves: [start..mid-1] and [mid..end-1]\n",
    "            int i = start, j = mid, k = 0;\n",
    "            int* temp=(int*)malloc(2 * step * sizeof(int));\n",
    "\n",
    "            while (i < mid && j < end)\n",
    "                temp[k++] = (sharedMem[i] < sharedMem[j]) ? sharedMem[i++] : sharedMem[j++];\n",
    "            while (i < mid)\n",
    "                temp[k++] = sharedMem[i++];\n",
    "            while (j < end)\n",
    "                temp[k++] = sharedMem[j++];\n",
    "\n",
    "            // Copy back to shared memory\n",
    "            for (int m = 0; m < (end - start); m++)\n",
    "                sharedMem[start + m] = temp[m];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (blockStart + tid < N)\n",
    "        d_output[blockStart + tid] = sharedMem[tid];\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int h_input[N], h_output[N];\n",
    "    int *d_input, *d_output;\n",
    "\n",
    "    printf(\"Unsorted array:\\n\");\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_input[i] = rand() % 100;\n",
    "        printf(\"%d \", h_input[i]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "\n",
    "    cudaMalloc(&d_input, N * sizeof(int));\n",
    "    cudaMalloc(&d_output, N * sizeof(int));\n",
    "\n",
    "    cudaMemcpy(d_input, h_input, N * sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 grid((N + BLOCK_SIZE - 1) / BLOCK_SIZE);\n",
    "    dim3 block(BLOCK_SIZE);\n",
    "\n",
    "    mergeSortShared<<<grid, block>>>(d_input, d_output, N);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    cudaMemcpy(h_output, d_output, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    printf(\"\\nSorted array:\\n\");\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        printf(\"%d \", h_output[i]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b053a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array:\n",
      "41 67 34 0 69 24 78 58 62 64 5 45 81 27 61 91 95 42 27 36 91 4 2 53 92 82 21 16 18 95 47 26 \n",
      "\n",
      "Sorted array:\n",
      "0 2 4 5 16 18 21 24 26 27 27 34 36 41 42 45 47 53 58 61 62 64 67 69 78 81 82 91 91 92 95 95 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N 32\n",
    "#define BLOCK_SIZE 16\n",
    "\n",
    "__global__ \n",
    "void blockSort(int *d_in, int *d_out) {\n",
    "    __shared__ \n",
    "    int s_data[BLOCK_SIZE];\n",
    "\n",
    "    int tid = threadIdx.x;\n",
    "    int gid = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (gid < N)\n",
    "        s_data[tid] = d_in[gid];\n",
    "    __syncthreads();\n",
    "\n",
    "    for (int i = 0; i < BLOCK_SIZE; i++) {\n",
    "        for (int j = 0; j < BLOCK_SIZE - i - 1; j++) {\n",
    "            if (s_data[j] > s_data[j + 1]) {\n",
    "                int temp = s_data[j];\n",
    "                s_data[j] = s_data[j + 1];\n",
    "                s_data[j + 1] = temp;\n",
    "            }\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (gid < N)\n",
    "        d_out[gid] = s_data[tid];\n",
    "}\n",
    "\n",
    "__global__ \n",
    "void globalMerge(int *input, int *output, int width) {\n",
    "    \n",
    "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    int start1 = 2 * width * blockIdx.x;\n",
    "    int start2 = start1 + width;\n",
    "    int end1 = start2;\n",
    "    int end2 = min(start2 + width, N);\n",
    "    \n",
    "    int i = start1, j = start2, k = start1;\n",
    "\n",
    "    while (i < end1 && j < end2) {\n",
    "        output[k++] = (input[i] < input[j]) ? input[i++] : input[j++];\n",
    "    }\n",
    "    while (i < end1) output[k++] = input[i++];\n",
    "    while (j < end2) output[k++] = input[j++];\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int h_input[N], h_output[N];\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_input[i] = rand() % 100;\n",
    "    }\n",
    "\n",
    "    printf(\"Original array:\\n\");\n",
    "    for (int i = 0; i < N; i++) printf(\"%d \", h_input[i]);\n",
    "    printf(\"\\n\");\n",
    "\n",
    "    int *d_input, *d_output;\n",
    "    cudaMalloc(&d_input, N * sizeof(int));\n",
    "    cudaMalloc(&d_output, N * sizeof(int));\n",
    "\n",
    "    cudaMemcpy(d_input, h_input, N * sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    blockSort<<<N / BLOCK_SIZE, BLOCK_SIZE>>>(d_input, d_output);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    int *temp;\n",
    "    for (int width = BLOCK_SIZE; width < N; width *= 2) {\n",
    "        int blocks = N / (2 * width);\n",
    "        globalMerge<<<blocks, 1>>>(d_output, d_input, width);\n",
    "        cudaDeviceSynchronize();\n",
    "\n",
    "        temp = d_output;\n",
    "        d_output = d_input;\n",
    "        d_input = temp;\n",
    "    }\n",
    "\n",
    "    cudaMemcpy(h_output, d_output, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    printf(\"\\nSorted array:\\n\");\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        printf(\"%d \", h_output[i]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "\n",
    "    cudaFree(d_input);\n",
    "    cudaFree(d_output);\n",
    "    return 0;\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
