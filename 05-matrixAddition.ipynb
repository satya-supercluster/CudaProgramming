{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d54cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "%pip install nvcc4jupyter\n",
    "%load_ext nvcc4jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30a257db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "0.0 1.0 2.0 3.0 \n",
      "16.0 17.0 18.0 19.0 \n",
      "32.0 33.0 34.0 35.0 \n",
      "48.0 49.0 50.0 51.0 \n",
      "\n",
      "B:\n",
      "0.0 1.0 2.0 3.0 \n",
      "16.0 17.0 18.0 19.0 \n",
      "32.0 33.0 34.0 35.0 \n",
      "48.0 49.0 50.0 51.0 \n",
      "\n",
      "C:\n",
      "0.0 2.0 4.0 6.0 \n",
      "32.0 34.0 36.0 38.0 \n",
      "64.0 66.0 68.0 70.0 \n",
      "96.0 98.0 100.0 102.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "#define N 16\n",
    "\n",
    "__global__ \n",
    "void matrixAdd(const float *A, const float *B, float *C, int width) {\n",
    "    \n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int idx = row * width + col;\n",
    "\n",
    "    if (row < width && col < width) {\n",
    "        C[idx] = A[idx] + B[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int size = N * N;\n",
    "    size_t sz = size * sizeof(float);\n",
    "\n",
    "    float *h_A = (float*)malloc(sz);\n",
    "    float *h_B = (float*)malloc(sz);\n",
    "    float *h_C = (float*)malloc(sz);\n",
    "\n",
    "    for (int i = 0; i < size; i++) {\n",
    "        h_A[i] = i;\n",
    "        h_B[i] = i;\n",
    "    }\n",
    "\n",
    "    float *d_A, *d_B, *d_C;\n",
    "    cudaMalloc((void**)&d_A, sz);\n",
    "    cudaMalloc((void**)&d_B, sz);\n",
    "    cudaMalloc((void**)&d_C, sz);\n",
    "\n",
    "    cudaMemcpy(d_A, h_A, sz, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, sz, cudaMemcpyHostToDevice);\n",
    "\n",
    "    int THREADS = 16;\n",
    "    dim3 threadsPerBlock(THREADS, THREADS);\n",
    "    dim3 blocksPerGrid((N + THREADS - 1) / THREADS, (N + THREADS - 1) / THREADS);\n",
    "\n",
    "    \n",
    "    matrixAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    cudaMemcpy(h_C, d_C, sz, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    printf(\"A:\\n\");\n",
    "    for (int row = 0; row < 4; row++) {\n",
    "        for (int col = 0; col < 4; col++) {\n",
    "            printf(\"%0.1f \", h_A[row * N + col]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "    printf(\"\\nB:\\n\");\n",
    "    for (int row = 0; row < 4; row++) {\n",
    "        for (int col = 0; col < 4; col++) {\n",
    "            printf(\"%0.1f \", h_B[row * N + col]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "    printf(\"\\nC:\\n\");\n",
    "    for (int row = 0; row < 4; row++) {\n",
    "        for (int col = 0; col < 4; col++) {\n",
    "            printf(\"%0.1f \", h_C[row * N + col]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(h_C);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
